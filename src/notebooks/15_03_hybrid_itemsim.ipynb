{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_reader import DataReader\n",
    "from src.constant import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.datasets.dataset import Dataset\n",
    "from src.models.itemknn.itemknn import ItemKNN\n",
    "from src.models.ease.ease import EASE\n",
    "from src.models.content_ease.content_ease import CEASE\n",
    "from src.models.hybrid_item_sim.hybrid_item_sim import HybridItemSimilarity\n",
    "import pandas as pd\n",
    "from src.evaluation import compute_mrr, map_at_k\n",
    "from src.utils.sparse_matrix import interactions_to_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = dataset.get_split()\n",
    "train, train_label = split_dict[TRAIN]\n",
    "val, val_label = split_dict[VAL]\n",
    "test, test_label = split_dict[TEST]\n",
    "\n",
    "val_test = pd.concat([val, test])\n",
    "val_test_label = pd.concat([val_label, test_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "max_date = train[DATE].max()\n",
    "train_limit_date = max_date - timedelta(days=150)\n",
    "filtered_train = train[train[DATE] > train_limit_date].copy()\n",
    "id_filtered_train = filtered_train[SESS_ID].unique()\n",
    "\n",
    "final_train_data = train[train[SESS_ID].isin(id_filtered_train)]\n",
    "final_train_label = train_label[train_label[SESS_ID].isin(id_filtered_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = dataset.get_train_sessions()\n",
    "# we can not use that for the final submission\n",
    "lead_data = dataset.get_test_leaderboard_sessions()\n",
    "final_data = dataset.get_test_final_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1469753/3772025307.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_train_data[\"sample_weight\"] = 1\n",
      "/tmp/ipykernel_1469753/3772025307.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_train_label[\"sample_weight\"] = 5\n"
     ]
    }
   ],
   "source": [
    "train[\"sample_weight\"] = 1\n",
    "train_label[\"sample_weight\"] = 5\n",
    "\n",
    "final_train_data[\"sample_weight\"] = 1\n",
    "final_train_label[\"sample_weight\"] = 5\n",
    "\n",
    "val[\"sample_weight\"] = 1\n",
    "val_label[\"sample_weight\"] = 5\n",
    "\n",
    "test[\"sample_weight\"] = 1\n",
    "test_label[\"sample_weight\"] = 5\n",
    "\n",
    "lead_data[\"sample_weight\"] = 1\n",
    "final_data[\"sample_weight\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pur = pd.concat([final_train_data, final_train_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cease = CEASE(dataset, time_weight=None, l2=1e-1)\n",
    "ease = EASE(dataset, time_weight=None, l2=1e-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.7]\n"
     ]
    }
   ],
   "source": [
    "hybrid_m = HybridItemSimilarity(dataset=dataset, model_list=[ease, cease], model_weight_list=[0.3, 0.7],\n",
    "                                normalization=None, normalization_axis=1, time_weight=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23691, 23691)\n",
      "Computing inverse\n"
     ]
    }
   ],
   "source": [
    "hybrid_m.compute_similarity_matrix(train_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Time Weight on Interaction matrix\n",
      "Considering white list items...\n"
     ]
    }
   ],
   "source": [
    "recs = hybrid_m.recommend(\n",
    "    interactions=val_test,\n",
    "    remove_seen=True,\n",
    "    cutoff=100,\n",
    "    leaderboard=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.1856782616100282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1856782616100282"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mrr(recs, val_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs.reset_index(drop=True).to_feather(dataset.get_train_recs_df_folder() / \"hybrid_ease_tw.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_full_data = pd.concat([final_train_data, final_train_label, val, val_label, test, test_label], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cease = CEASE(dataset, time_weight=None, l2=1e-1)\n",
    "ease = EASE(dataset, time_weight=None, l2=1e-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.7]\n"
     ]
    }
   ],
   "source": [
    "hybrid_m = HybridItemSimilarity(dataset=dataset, model_list=[ease, cease], model_weight_list=[0.3, 0.7],\n",
    "                                normalization=None, normalization_axis=1, time_weight=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23691, 23691)\n",
      "Computing inverse\n"
     ]
    }
   ],
   "source": [
    "hybrid_m.compute_similarity_matrix(concat_full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Time Weight on Interaction matrix\n",
      "Considering white list items...\n"
     ]
    }
   ],
   "source": [
    "recs_lead = hybrid_m.recommend(\n",
    "    interactions=lead_data,\n",
    "    remove_seen=True,\n",
    "    cutoff=100,\n",
    "    leaderboard=True\n",
    ")\n",
    "recs_lead.reset_index(drop=True).to_feather(dataset.get_leaderboard_recs_df_folder() / \"hybrid_ease_tw.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Time Weight on Interaction matrix\n",
      "Considering white list items...\n"
     ]
    }
   ],
   "source": [
    "recs_final = hybrid_m.recommend(\n",
    "    interactions=final_data,\n",
    "    remove_seen=True,\n",
    "    cutoff=100,\n",
    "    leaderboard=True\n",
    ")\n",
    "recs_final.reset_index(drop=True).to_feather(dataset.get_final_recs_df_folder() / \"hybrid_ease_tw.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.create_submission(recs, sub_name=\"CEASE_tw50_0.3_0.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3c183c6e04ae4d2393ea2f09069167a37db434d2fc961fc183b2481fc93012"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
